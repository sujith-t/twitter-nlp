{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ca0906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_news_scraper as tns\n",
    "import text_normalizer as tn\n",
    "import extractor as ex\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, date\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# prepare parameters to find tweets with news\n",
    "# to_date = date.today()\n",
    "to_date = datetime(2022, 6, 1)\n",
    "from_date = datetime(to_date.year - 1, to_date.month, to_date.day)\n",
    "query = '\"sports news\" (cricket OR hockey OR football OR rugger OR tennis OR badminton OR volleyball OR \\\n",
    "race OR racing OR swimming OR gymnastics OR diving OR polo) lang:en'\n",
    "\n",
    "# csv file where news items are saved\n",
    "output_file = os.getcwd() + '\\\\news_items.csv'\n",
    "\n",
    "# deduplicated news items\n",
    "dedup_file = os.getcwd() + '\\\\dedup_items.csv'\n",
    "\n",
    "# normalized train and test news items\n",
    "train_norm_file = os.getcwd() + '\\\\train_normalized.csv'\n",
    "test_norm_file = os.getcwd() + '\\\\test_normalized.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c628b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News items found : 5\n"
     ]
    }
   ],
   "source": [
    "# extract tweet news, no need to execute this step as already data is gathered in CSV file\n",
    "news_tweets = tns.find_tweets_with_news(from_date, to_date, query, 20000, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d413be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract news from twitter newslinks, no need to execute this step as already data is gathered in CSV file\n",
    "tns.extract_news(news_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3250e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional step to save all news tweets and news text to csv file. Already done\n",
    "news_tweets.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425ef531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project\\assignment\\Text_Analytics\\twitter-nlp\\news_items.csv\n"
     ]
    }
   ],
   "source": [
    "# Since already data is gathered and saved in CSV, this step will quickly load it to dataframe\n",
    "# recommended to follow this step\n",
    "news_tweets = pd.read_csv(output_file)\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48887ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences [0-100] Words [0-200] Unique Words [0-100] : 3654\n",
      "Sentences [0-100] Words [0-200] Unique Words [100-200] : 8\n",
      "Sentences [0-100] Words [200-400] Unique Words [0-100] : 1\n",
      "Sentences [0-100] Words [200-400] Unique Words [100-200] : 26\n",
      "Sentences [0-100] Words [200-400] Unique Words [200-300] : 39\n",
      "Sentences [0-100] Words [400-600] Unique Words [100-200] : 8\n",
      "Sentences [0-100] Words [400-600] Unique Words [200-300] : 150\n",
      "Sentences [0-100] Words [400-600] Unique Words [300-400] : 41\n",
      "Sentences [0-100] Words [600-800] Unique Words [100-200] : 4\n",
      "Sentences [0-100] Words [600-800] Unique Words [200-300] : 17\n",
      "Sentences [0-100] Words [600-800] Unique Words [300-400] : 199\n",
      "Sentences [0-100] Words [600-800] Unique Words [400-500] : 42\n",
      "Sentences [0-100] Words [600-800] Unique Words [500-600] : 1\n",
      "Sentences [0-100] Words [800-1000] Unique Words [100-200] : 2\n",
      "Sentences [0-100] Words [800-1000] Unique Words [200-300] : 3\n",
      "Sentences [0-100] Words [800-1000] Unique Words [300-400] : 55\n",
      "Sentences [0-100] Words [800-1000] Unique Words [400-500] : 144\n",
      "Sentences [0-100] Words [800-1000] Unique Words [500-600] : 15\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [200-300] : 26\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [300-400] : 15\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [400-500] : 102\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [500-600] : 105\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [600-700] : 13\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [200-300] : 8\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [300-400] : 12\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [400-500] : 18\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [500-600] : 101\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [600-700] : 78\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [700-800] : 2\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [200-300] : 6\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [300-400] : 3\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [400-500] : 13\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [500-600] : 21\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [600-700] : 61\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [700-800] : 10\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [400-500] : 7\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [500-600] : 12\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [600-700] : 16\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [700-800] : 29\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [800-900] : 13\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [500-600] : 5\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [600-700] : 2\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [700-800] : 9\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [800-900] : 14\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [500-600] : 3\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [600-700] : 3\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [700-800] : 2\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [800-900] : 5\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [900-1000] : 5\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [700-800] : 4\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [800-900] : 9\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [1100-1200] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [400-500] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [800-900] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [900-1000] : 18\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [1000-1100] : 2\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [1100-1200] : 3\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [500-600] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [800-900] : 3\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [1100-1200] : 6\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [1400-1500] : 1\n",
      "Sentences [0-100] Words [2800-3000] Unique Words [900-1000] : 3\n",
      "Sentences [0-100] Words [2800-3000] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [2800-3000] Unique Words [1100-1200] : 8\n",
      "Sentences [0-100] Words [3000-3200] Unique Words [1200-1300] : 3\n",
      "Sentences [0-100] Words [3200-3400] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [3200-3400] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [3200-3400] Unique Words [1100-1200] : 1\n",
      "Sentences [0-100] Words [3400-3600] Unique Words [700-800] : 1\n",
      "Sentences [0-100] Words [5000-5200] Unique Words [1500-1600] : 1\n",
      "Sentences [0-100] Words [5000-5200] Unique Words [1600-1700] : 1\n",
      "Sentences [0-100] Words [5200-5400] Unique Words [1500-1600] : 1\n",
      "Sentences [0-100] Words [5200-5400] Unique Words [1600-1700] : 9\n",
      "Sentences [0-100] Words [5200-5400] Unique Words [1700-1800] : 1\n",
      "Sentences [0-100] Words [5400-5600] Unique Words [1500-1600] : 1\n",
      "Sentences [0-100] Words [5600-5800] Unique Words [1700-1800] : 1\n",
      "Sentences [0-100] Words [11800-12000] Unique Words [3400-3500] : 1\n",
      "Sentences [100-200] Words [1000-1200] Unique Words [300-400] : 4\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [300-400] : 7\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [400-500] : 17\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [500-600] : 1\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [600-700] : 1\n",
      "Sentences [100-200] Words [1400-1600] Unique Words [400-500] : 16\n",
      "Sentences [100-200] Words [1400-1600] Unique Words [500-600] : 4\n",
      "Sentences [100-200] Words [1400-1600] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [1600-1800] Unique Words [400-500] : 3\n",
      "Sentences [100-200] Words [1600-1800] Unique Words [500-600] : 18\n",
      "Sentences [100-200] Words [1600-1800] Unique Words [600-700] : 1\n",
      "Sentences [100-200] Words [1800-2000] Unique Words [400-500] : 1\n",
      "Sentences [100-200] Words [1800-2000] Unique Words [500-600] : 6\n",
      "Sentences [100-200] Words [1800-2000] Unique Words [600-700] : 8\n",
      "Sentences [100-200] Words [1800-2000] Unique Words [700-800] : 3\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [500-600] : 2\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [700-800] : 12\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [800-900] : 4\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [500-600] : 2\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [700-800] : 3\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [800-900] : 1\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [900-1000] : 4\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [1000-1100] : 1\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [700-800] : 1\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [800-900] : 4\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [900-1000] : 2\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [700-800] : 3\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [800-900] : 2\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [900-1000] : 1\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [1000-1100] : 1\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [1200-1300] : 2\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [600-700] : 4\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [700-800] : 2\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [800-900] : 1\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [900-1000] : 3\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [1000-1100] : 4\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [1300-1400] : 2\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [500-600] : 1\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [800-900] : 3\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [1000-1100] : 2\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [1100-1200] : 1\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [900-1000] : 2\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [1000-1100] : 2\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [1100-1200] : 1\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [1200-1300] : 1\n",
      "Sentences [100-200] Words [3400-3600] Unique Words [700-800] : 1\n",
      "Sentences [100-200] Words [3400-3600] Unique Words [800-900] : 1\n",
      "Sentences [100-200] Words [3400-3600] Unique Words [1200-1300] : 2\n",
      "Sentences [100-200] Words [3600-3800] Unique Words [1300-1400] : 1\n",
      "Sentences [100-200] Words [3800-4000] Unique Words [800-900] : 1\n",
      "Sentences [100-200] Words [3800-4000] Unique Words [1000-1100] : 1\n",
      "Sentences [100-200] Words [4400-4600] Unique Words [1000-1100] : 1\n",
      "Sentences [100-200] Words [4400-4600] Unique Words [1100-1200] : 1\n",
      "Sentences [100-200] Words [4400-4600] Unique Words [1400-1500] : 1\n",
      "Sentences [100-200] Words [4800-5000] Unique Words [1400-1500] : 7\n",
      "Sentences [100-200] Words [5600-5800] Unique Words [1700-1800] : 1\n",
      "Sentences [100-200] Words [5800-6000] Unique Words [1700-1800] : 2\n",
      "Sentences [100-200] Words [6800-7000] Unique Words [1500-1600] : 1\n",
      "Sentences [100-200] Words [12800-13000] Unique Words [3600-3700] : 1\n",
      "Sentences [200-300] Words [1400-1600] Unique Words [400-500] : 1\n",
      "Sentences [200-300] Words [1600-1800] Unique Words [500-600] : 3\n",
      "Sentences [200-300] Words [1800-2000] Unique Words [500-600] : 6\n",
      "Sentences [200-300] Words [1800-2000] Unique Words [600-700] : 2\n",
      "Sentences [200-300] Words [2000-2200] Unique Words [500-600] : 3\n",
      "Sentences [200-300] Words [2000-2200] Unique Words [600-700] : 14\n",
      "Sentences [200-300] Words [2200-2400] Unique Words [500-600] : 4\n",
      "Sentences [200-300] Words [2200-2400] Unique Words [600-700] : 15\n",
      "Sentences [200-300] Words [2200-2400] Unique Words [700-800] : 1\n",
      "Sentences [200-300] Words [2400-2600] Unique Words [600-700] : 3\n",
      "Sentences [200-300] Words [2400-2600] Unique Words [700-800] : 3\n",
      "Sentences [200-300] Words [2400-2600] Unique Words [1000-1100] : 1\n",
      "Sentences [200-300] Words [2600-2800] Unique Words [600-700] : 2\n",
      "Sentences [200-300] Words [2600-2800] Unique Words [700-800] : 3\n",
      "Sentences [200-300] Words [2600-2800] Unique Words [800-900] : 2\n",
      "Sentences [200-300] Words [2800-3000] Unique Words [700-800] : 2\n",
      "Sentences [200-300] Words [2800-3000] Unique Words [800-900] : 3\n",
      "Sentences [200-300] Words [2800-3000] Unique Words [1300-1400] : 1\n",
      "Sentences [200-300] Words [3000-3200] Unique Words [800-900] : 6\n",
      "Sentences [200-300] Words [3200-3400] Unique Words [800-900] : 1\n",
      "Sentences [200-300] Words [3200-3400] Unique Words [1500-1600] : 1\n",
      "Sentences [200-300] Words [3400-3600] Unique Words [700-800] : 2\n",
      "Sentences [200-300] Words [3600-3800] Unique Words [500-600] : 1\n",
      "Sentences [200-300] Words [3600-3800] Unique Words [600-700] : 1\n",
      "Sentences [200-300] Words [3800-4000] Unique Words [1000-1100] : 1\n",
      "Sentences [200-300] Words [4000-4200] Unique Words [900-1000] : 1\n",
      "Sentences [200-300] Words [4000-4200] Unique Words [1000-1100] : 3\n",
      "Sentences [200-300] Words [4200-4400] Unique Words [600-700] : 1\n",
      "Sentences [200-300] Words [4200-4400] Unique Words [700-800] : 1\n",
      "Sentences [200-300] Words [4800-5000] Unique Words [1000-1100] : 1\n",
      "Sentences [200-300] Words [5000-5200] Unique Words [1300-1400] : 1\n",
      "Sentences [200-300] Words [5400-5600] Unique Words [1300-1400] : 1\n",
      "Sentences [200-300] Words [6200-6400] Unique Words [1300-1400] : 1\n",
      "Sentences [300-400] Words [3400-3600] Unique Words [700-800] : 1\n",
      "Sentences [300-400] Words [4000-4200] Unique Words [1000-1100] : 2\n",
      "Sentences [300-400] Words [4200-4400] Unique Words [1000-1100] : 1\n",
      "Sentences [300-400] Words [4600-4800] Unique Words [1100-1200] : 1\n",
      "Sentences [300-400] Words [5600-5800] Unique Words [1200-1300] : 1\n",
      "Sentences [300-400] Words [5800-6000] Unique Words [1200-1300] : 1\n",
      "Sentences [300-400] Words [6200-6400] Unique Words [1400-1500] : 1\n",
      "Sentences [300-400] Words [8800-9000] Unique Words [1600-1700] : 2\n",
      "Sentences [400-500] Words [5200-5400] Unique Words [600-700] : 5\n",
      "Sentences [400-500] Words [5400-5600] Unique Words [700-800] : 3\n",
      "Sentences [500-600] Words [3800-4000] Unique Words [800-900] : 1\n",
      "Sentences [500-600] Words [7200-7400] Unique Words [1500-1600] : 1\n",
      "Sentences [700-800] Words [8000-8200] Unique Words [1300-1400] : 1\n",
      "Sentences [700-800] Words [11200-11400] Unique Words [2200-2300] : 2\n",
      "Sentences [800-900] Words [11800-12000] Unique Words [2500-2600] : 1\n",
      "Sentences [1600-1700] Words [28200-28400] Unique Words [4300-4400] : 1\n",
      "\n",
      "Summary\n",
      "------------\n",
      "Total tweets collected : 7484\n",
      "Valid news items : 5532\n",
      "Tweets has expired or invalid news links: 1952\n"
     ]
    }
   ],
   "source": [
    "# Provide details of sentences, words, unique words distribution stats\n",
    "# creating a new column will help to save unique words for future processing\n",
    "news_tweets[\"unique_words\"] = None\n",
    "news_tweets = news_tweets.drop(columns=['date', 'user', 'tweet'])\n",
    "news_tweets = tns.describe_news_statistics(news_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f6551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences [0-100] Words [0-200] Unique Words [0-100] : 50\n",
      "Sentences [0-100] Words [0-200] Unique Words [100-200] : 8\n",
      "Sentences [0-100] Words [200-400] Unique Words [100-200] : 22\n",
      "Sentences [0-100] Words [200-400] Unique Words [200-300] : 30\n",
      "Sentences [0-100] Words [400-600] Unique Words [100-200] : 6\n",
      "Sentences [0-100] Words [400-600] Unique Words [200-300] : 103\n",
      "Sentences [0-100] Words [400-600] Unique Words [300-400] : 29\n",
      "Sentences [0-100] Words [600-800] Unique Words [100-200] : 4\n",
      "Sentences [0-100] Words [600-800] Unique Words [200-300] : 12\n",
      "Sentences [0-100] Words [600-800] Unique Words [300-400] : 113\n",
      "Sentences [0-100] Words [600-800] Unique Words [400-500] : 25\n",
      "Sentences [0-100] Words [600-800] Unique Words [500-600] : 1\n",
      "Sentences [0-100] Words [800-1000] Unique Words [100-200] : 1\n",
      "Sentences [0-100] Words [800-1000] Unique Words [200-300] : 3\n",
      "Sentences [0-100] Words [800-1000] Unique Words [300-400] : 23\n",
      "Sentences [0-100] Words [800-1000] Unique Words [400-500] : 103\n",
      "Sentences [0-100] Words [800-1000] Unique Words [500-600] : 12\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [200-300] : 21\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [300-400] : 7\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [400-500] : 51\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [500-600] : 79\n",
      "Sentences [0-100] Words [1000-1200] Unique Words [600-700] : 13\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [200-300] : 4\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [300-400] : 7\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [400-500] : 5\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [500-600] : 77\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [600-700] : 65\n",
      "Sentences [0-100] Words [1200-1400] Unique Words [700-800] : 2\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [300-400] : 1\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [400-500] : 8\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [500-600] : 15\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [600-700] : 39\n",
      "Sentences [0-100] Words [1400-1600] Unique Words [700-800] : 6\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [400-500] : 6\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [500-600] : 9\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [600-700] : 9\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [700-800] : 20\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [800-900] : 7\n",
      "Sentences [0-100] Words [1600-1800] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [500-600] : 3\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [600-700] : 2\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [700-800] : 6\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [800-900] : 12\n",
      "Sentences [0-100] Words [1800-2000] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [500-600] : 3\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [800-900] : 3\n",
      "Sentences [0-100] Words [2000-2200] Unique Words [900-1000] : 4\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [700-800] : 2\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [800-900] : 6\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2200-2400] Unique Words [1100-1200] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [400-500] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [1000-1100] : 2\n",
      "Sentences [0-100] Words [2400-2600] Unique Words [1100-1200] : 2\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [500-600] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [600-700] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [800-900] : 2\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [1100-1200] : 3\n",
      "Sentences [0-100] Words [2600-2800] Unique Words [1400-1500] : 1\n",
      "Sentences [0-100] Words [2800-3000] Unique Words [900-1000] : 1\n",
      "Sentences [0-100] Words [2800-3000] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [2800-3000] Unique Words [1100-1200] : 4\n",
      "Sentences [0-100] Words [3000-3200] Unique Words [1200-1300] : 1\n",
      "Sentences [0-100] Words [3200-3400] Unique Words [1000-1100] : 1\n",
      "Sentences [0-100] Words [11800-12000] Unique Words [3400-3500] : 1\n",
      "Sentences [100-200] Words [1000-1200] Unique Words [300-400] : 4\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [300-400] : 7\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [400-500] : 17\n",
      "Sentences [100-200] Words [1200-1400] Unique Words [500-600] : 1\n",
      "Sentences [100-200] Words [1400-1600] Unique Words [400-500] : 15\n",
      "Sentences [100-200] Words [1400-1600] Unique Words [500-600] : 4\n",
      "Sentences [100-200] Words [1400-1600] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [1600-1800] Unique Words [400-500] : 3\n",
      "Sentences [100-200] Words [1600-1800] Unique Words [500-600] : 18\n",
      "Sentences [100-200] Words [1600-1800] Unique Words [600-700] : 1\n",
      "Sentences [100-200] Words [1800-2000] Unique Words [500-600] : 6\n",
      "Sentences [100-200] Words [1800-2000] Unique Words [600-700] : 7\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [500-600] : 2\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [700-800] : 7\n",
      "Sentences [100-200] Words [2000-2200] Unique Words [800-900] : 2\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [500-600] : 1\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [600-700] : 1\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [700-800] : 3\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [800-900] : 1\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [900-1000] : 1\n",
      "Sentences [100-200] Words [2200-2400] Unique Words [1000-1100] : 1\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [600-700] : 1\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [700-800] : 1\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [800-900] : 3\n",
      "Sentences [100-200] Words [2400-2600] Unique Words [900-1000] : 2\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [700-800] : 1\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [800-900] : 2\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [900-1000] : 1\n",
      "Sentences [100-200] Words [2600-2800] Unique Words [1200-1300] : 2\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [600-700] : 2\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [700-800] : 2\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [900-1000] : 3\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [1000-1100] : 4\n",
      "Sentences [100-200] Words [2800-3000] Unique Words [1300-1400] : 2\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [500-600] : 1\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [800-900] : 2\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [1000-1100] : 1\n",
      "Sentences [100-200] Words [3000-3200] Unique Words [1100-1200] : 1\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [900-1000] : 1\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [1000-1100] : 2\n",
      "Sentences [100-200] Words [3200-3400] Unique Words [1100-1200] : 1\n",
      "Sentences [100-200] Words [3400-3600] Unique Words [700-800] : 1\n",
      "Sentences [100-200] Words [3400-3600] Unique Words [1200-1300] : 1\n",
      "Sentences [100-200] Words [3800-4000] Unique Words [800-900] : 1\n",
      "Sentences [100-200] Words [4400-4600] Unique Words [1400-1500] : 1\n",
      "Sentences [100-200] Words [6800-7000] Unique Words [1500-1600] : 1\n",
      "Sentences [100-200] Words [12800-13000] Unique Words [3600-3700] : 1\n",
      "Sentences [200-300] Words [1400-1600] Unique Words [400-500] : 1\n",
      "Sentences [200-300] Words [1600-1800] Unique Words [500-600] : 3\n",
      "Sentences [200-300] Words [1800-2000] Unique Words [500-600] : 6\n",
      "Sentences [200-300] Words [1800-2000] Unique Words [600-700] : 2\n",
      "Sentences [200-300] Words [2000-2200] Unique Words [500-600] : 3\n",
      "Sentences [200-300] Words [2000-2200] Unique Words [600-700] : 12\n",
      "Sentences [200-300] Words [2200-2400] Unique Words [500-600] : 4\n",
      "Sentences [200-300] Words [2200-2400] Unique Words [600-700] : 15\n",
      "Sentences [200-300] Words [2200-2400] Unique Words [700-800] : 1\n",
      "Sentences [200-300] Words [2400-2600] Unique Words [600-700] : 3\n",
      "Sentences [200-300] Words [2400-2600] Unique Words [700-800] : 3\n",
      "Sentences [200-300] Words [2400-2600] Unique Words [1000-1100] : 1\n",
      "Sentences [200-300] Words [2600-2800] Unique Words [600-700] : 2\n",
      "Sentences [200-300] Words [2600-2800] Unique Words [700-800] : 3\n",
      "Sentences [200-300] Words [2600-2800] Unique Words [800-900] : 2\n",
      "Sentences [200-300] Words [2800-3000] Unique Words [700-800] : 2\n",
      "Sentences [200-300] Words [2800-3000] Unique Words [800-900] : 3\n",
      "Sentences [200-300] Words [2800-3000] Unique Words [1300-1400] : 1\n",
      "Sentences [200-300] Words [3000-3200] Unique Words [800-900] : 6\n",
      "Sentences [200-300] Words [3200-3400] Unique Words [800-900] : 1\n",
      "Sentences [200-300] Words [3200-3400] Unique Words [1500-1600] : 1\n",
      "Sentences [200-300] Words [3400-3600] Unique Words [700-800] : 2\n",
      "Sentences [200-300] Words [3600-3800] Unique Words [500-600] : 1\n",
      "Sentences [200-300] Words [3600-3800] Unique Words [600-700] : 1\n",
      "Sentences [200-300] Words [3800-4000] Unique Words [1000-1100] : 1\n",
      "Sentences [200-300] Words [4000-4200] Unique Words [900-1000] : 1\n",
      "Sentences [200-300] Words [4000-4200] Unique Words [1000-1100] : 1\n",
      "Sentences [200-300] Words [4200-4400] Unique Words [600-700] : 1\n",
      "Sentences [200-300] Words [4200-4400] Unique Words [700-800] : 1\n",
      "Sentences [200-300] Words [5000-5200] Unique Words [1300-1400] : 1\n",
      "Sentences [200-300] Words [5400-5600] Unique Words [1300-1400] : 1\n",
      "Sentences [200-300] Words [6200-6400] Unique Words [1300-1400] : 1\n",
      "Sentences [300-400] Words [3400-3600] Unique Words [700-800] : 1\n",
      "Sentences [300-400] Words [4000-4200] Unique Words [1000-1100] : 1\n",
      "Sentences [300-400] Words [4200-4400] Unique Words [1000-1100] : 1\n",
      "Sentences [300-400] Words [4600-4800] Unique Words [1100-1200] : 1\n",
      "Sentences [300-400] Words [5600-5800] Unique Words [1200-1300] : 1\n",
      "Sentences [300-400] Words [5800-6000] Unique Words [1200-1300] : 1\n",
      "Sentences [300-400] Words [6200-6400] Unique Words [1400-1500] : 1\n",
      "Sentences [300-400] Words [8800-9000] Unique Words [1600-1700] : 1\n",
      "Sentences [500-600] Words [3800-4000] Unique Words [800-900] : 1\n",
      "Sentences [500-600] Words [7200-7400] Unique Words [1500-1600] : 1\n",
      "Sentences [700-800] Words [8000-8200] Unique Words [1300-1400] : 1\n",
      "\n",
      "Summary\n",
      "------------\n",
      "Total tweets collected : 1313\n",
      "Valid news items : 1313\n",
      "Tweets has expired or invalid news links: 0\n"
     ]
    }
   ],
   "source": [
    "# --------The commented code can clean the news data gathered by finding the duplicates and remove them\n",
    "# --------and save them to dedup_items.csv file in the current directory--------------------------------\n",
    "\n",
    "# clean all duplicate news items based on 80% match probability by default. in here 95% accuracy\n",
    "dedup_df = tns.clean_duplicate_news(news_tweets, 95)\n",
    "\n",
    "# saving is optional, already the file is saved\n",
    "# dedup_df.to_csv(dedup_file, index=False)\n",
    "\n",
    "# read already created deduplicated dataset\n",
    "# dedup_df = pd.read_csv(dedup_file)\n",
    "# describe details of sentences, words, unique words distribution stats\n",
    "dedup_df = tns.describe_news_statistics(dedup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6215f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe 300 data for testing and the rest for training\n",
    "test_df = dedup_df.drop(columns=['unique_words']).sample(300)\n",
    "test_df[\"normalized\"] = None\n",
    "\n",
    "# training dataset\n",
    "train_df = dedup_df.drop(index=test_df.index, columns=['unique_words'])\n",
    "train_df[\"normalized\"] = None\n",
    "\n",
    "# pre-processing the data for feature extraction and saving them in csv file for quick reference\n",
    "# train_df = tn.normalize_text(train_df, True, True)\n",
    "# train_df = train_df.drop(columns=['news_text'])\n",
    "# train_df.to_csv(train_norm_file, index=False)\n",
    "\n",
    "# test_df = tn.normalize_text(test_df, True, True)\n",
    "# test_df = test_df.drop(columns=['news_text'])\n",
    "# test_df.to_csv(test_norm_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac98df30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News items per feature ranges distributions in 100s\n",
      " --------------------------------------------------\n",
      "Features 0-100 : 45 news items\n",
      "Features 100-200 : 34 news items\n",
      "Features 200-300 : 93 news items\n",
      "Features 300-400 : 88 news items\n",
      "Features 400-500 : 128 news items\n",
      "Features 500-600 : 116 news items\n",
      "Features 600-700 : 113 news items\n",
      "Features 700-800 : 105 news items\n",
      "Features 800-900 : 69 news items\n",
      "Features 900-1000 : 41 news items\n",
      "Features 1000-1100 : 39 news items\n",
      "Features 1100-1200 : 26 news items\n",
      "Features 1200-1300 : 21 news items\n",
      "Features 1300-1400 : 19 news items\n",
      "Features 1400-1500 : 16 news items\n",
      "Features 1500-1600 : 13 news items\n",
      "Features 1600-1700 : 10 news items\n",
      "Features 1700-1800 : 4 news items\n",
      "Features 1800-1900 : 3 news items\n",
      "Features 1900-2000 : 10 news items\n",
      "Features 2000-2100 : 4 news items\n",
      "Features 2100-2200 : 2 news items\n",
      "Features 2200-2300 : 1 news items\n",
      "Features 2300-2400 : 2 news items\n",
      "Features 2600-2700 : 2 news items\n",
      "Features 3000-3100 : 1 news items\n",
      "Features 3200-3300 : 1 news items\n",
      "Features 3400-3500 : 2 news items\n",
      "Features 3600-3700 : 1 news items\n",
      "Features 3900-4000 : 1 news items\n",
      "Features 4100-4200 : 1 news items\n",
      "Features 6200-6300 : 1 news items\n",
      "Features 6500-6600 : 1 news items\n",
      "\n",
      "Total news items - 1013\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_norm_file)\n",
    "test_df = pd.read_csv(test_norm_file)\n",
    "\n",
    "vectorizer, features = ex.bag_of_words_extractor(train_df[\"normalized\"].values.astype('U'))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_matrix = features.todense()\n",
    "\n",
    "# applying the same features on the test dataset\n",
    "test_features = vectorizer.transform(test_df[\"normalized\"].values.astype('U'))\n",
    "test_matrix = test_features.todense()\n",
    "\n",
    "# summarizes the feature distribution by feature ranges of 100\n",
    "ex.feature_summary(feature_matrix, feature_names, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15c196c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question f. build sports categorywise features to train on the train dataset\n",
    "categories = [\"cricket\", \"bowl\", \"batsman\", \"batting\", \"balling\", \"wicket\", \"runs\", \"goalkeeper\", \"hockey\", \n",
    "              \"football\", \"soccer\", \"rugger\", \"rugby\", \"tennis\", \"badminton\", \"volleyball\", \n",
    "              \"race\", \"racing\", \"swimming\", \"gymnastics\", \"diving\", \"polo\", \"baseball\", \n",
    "              \"chess\", \"shooting\", \"basketball\", \"golf\", \"catch\", \"boundary\", \"fifa\", \"freestyle\"]\n",
    "\n",
    "related_categories = {\"football\": [\"soccer\", \"goalkeeper\", \"fifa\"], \"rugby\": [\"rugger\"], \"race\": [\"racing\"], \n",
    "                      \"cricket\": [\"bowl\", \"batsman\", \"batting\", \"wicket\", \"runs\", \"catch\", \"boundary\", \"balling\"], \n",
    "                     \"swimming\": [\"freestyle\"]}\n",
    "\n",
    "# sportwise features\n",
    "category_features = ex.classify_category_features(feature_names, categories, related_categories)\n",
    "\n",
    "# generate categories for train dataset\n",
    "train_labels = ex.data_naivebayes_classify_categories(category_features, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8520b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Precision: 0.67\n",
      "Recall: 0.63\n",
      "F1 Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Question g. predict test data categories\n",
    "\n",
    "# To try SGDClassifier\n",
    "classifier = SGDClassifier(loss='hinge', max_iter=200)\n",
    "\n",
    "# predict labels for test dataset\n",
    "predictions = ex.train_predict_classification(classifier, features, train_labels, test_features)\n",
    "test_df[\"predicted\"] = predictions\n",
    "\n",
    "# print statistics of prediction\n",
    "ex.get_prediction_metrics_accuracy(test_df[\"category\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8103707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB Performance\n",
      "----------------------------\n",
      "Accuracy: 0.63\n",
      "Precision: 0.71\n",
      "Recall: 0.63\n",
      "F1 Score: 0.61\n",
      "\n",
      "SVM SVC Performance\n",
      "----------------------------\n",
      "Accuracy: 0.51\n",
      "Precision: 0.69\n",
      "Recall: 0.51\n",
      "F1 Score: 0.43\n",
      "\n",
      "KNN Classifier Performance\n",
      "----------------------------\n",
      "Accuracy: 0.51\n",
      "Precision: 0.61\n",
      "Recall: 0.51\n",
      "F1 Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Question h. Trying different scikit-learn algorithms to estimate predictability\n",
    "\n",
    "# To try MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "predictions = ex.train_predict_classification(classifier, features, train_labels, test_features)\n",
    "print(\"Multinomial NB Performance\\n----------------------------\")\n",
    "ex.get_prediction_metrics_accuracy(test_df[\"category\"], predictions)\n",
    "\n",
    "# Using SVM\n",
    "classifier = svm.SVC()\n",
    "predictions = ex.train_predict_classification(classifier, features, train_labels, test_features)\n",
    "print(\"\\nSVM SVC Performance\\n----------------------------\")\n",
    "ex.get_prediction_metrics_accuracy(test_df[\"category\"], predictions)\n",
    "\n",
    "# KNN classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "predictions = ex.train_predict_classification(classifier, features, train_labels, test_features)\n",
    "print(\"\\nKNN Classifier Performance\\n----------------------------\")\n",
    "ex.get_prediction_metrics_accuracy(test_df[\"category\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adc75472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - 107s 4s/step - loss: 2.3608 - accuracy: 0.3853 - val_loss: 2.1363 - val_accuracy: 0.3137\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 100s 3s/step - loss: 1.9445 - accuracy: 0.4171 - val_loss: 2.1218 - val_accuracy: 0.3137\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 103s 4s/step - loss: 1.9241 - accuracy: 0.4171 - val_loss: 2.0894 - val_accuracy: 0.3137\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 103s 4s/step - loss: 1.9219 - accuracy: 0.4171 - val_loss: 2.1105 - val_accuracy: 0.3137\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 103s 4s/step - loss: 1.9240 - accuracy: 0.4171 - val_loss: 2.0719 - val_accuracy: 0.3137\n"
     ]
    }
   ],
   "source": [
    "# Question i. Exploring Keras/Tensorflow library\n",
    "\n",
    "# import all libraries\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "\n",
    "# counts the occurance of unique words\n",
    "counter = ex.counter_word(train_df)\n",
    "max_length = 3700\n",
    "num_words = len(counter)\n",
    "\n",
    "train_corpus = train_df[\"normalized\"].values.astype('U')\n",
    "test_corpus = test_df[\"normalized\"].values.astype('U')\n",
    "\n",
    "# create a tokenizer and generate word index\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_corpus)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# build a sequence and padding for train data\n",
    "train_sequences = tokenizer.texts_to_sequences(train_corpus)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# build a sequence and padding for test data\n",
    "test_sequences = tokenizer.texts_to_sequences(test_corpus)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# prepare categorical labels for train and test data\n",
    "train_y = pd.get_dummies(train_labels).values\n",
    "test_y = pd.get_dummies(test_df[\"category\"]).values\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(17, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_padded, train_y, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e145fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 659ms/step - loss: 1.9920 - accuracy: 0.4046\n",
      "Test set\n",
      "  Loss: 1.992\n",
      "  Accuracy: 0.405\n"
     ]
    }
   ],
   "source": [
    "test_matrix = model.evaluate(test_padded,test_y)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(test_matrix[0], test_matrix[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0c31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
